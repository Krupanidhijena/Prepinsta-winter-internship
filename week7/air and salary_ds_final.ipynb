{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef69b29a-6f11-4ce4-9849-0d423a735046",
   "metadata": {},
   "source": [
    "# Week 7 Assignment\n",
    "## Indian Air Quality Data\n",
    "\n",
    "**Context:** Since industrialization, there has been an increasing concern about environmental pollution. As mentioned in the WHO report 7 million premature deaths annually are linked to air pollution, air pollution is the world's largest single environmental risk. Moreover as reported in the NY Times article, India’s Air Pollution Rivals China’s as World’s Deadliest it has been found that India's air pollution is deadlier than China's. We will explore India’s air pollution levels more granularly using this dataset.\n",
    "\n",
    "**Content:** This data is combined(across the years and states) and is largely a clean version of the Historical Daily Ambient Air Quality Data released by the Ministry of Environment and Forests and Central Pollution Control Board of India under the National Data Sharing and Accessibility Policy (NDSAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb80a0a3-1f0d-42ef-b5c0-4523f03f7c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as npy\n",
    "import pandas as pds\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning) # ignore warning messages\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f476bdb0-3ed4-48a8-8644-f8f1b20b2f4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\debar\\AppData\\Local\\Temp\\ipykernel_9960\\2827644914.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  air = pd.read_csv('E:/PrepInsta Winter Internship Program/Week 7/data-1.csv')\n"
     ]
    }
   ],
   "source": [
    "air = pds.read_csv('E:/PrepInsta Winter Internship Program/Week 7/data-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae4b079-636a-4853-ab7d-2aec5a8d1e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stn_code</th>\n",
       "      <th>sampling_date</th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>agency</th>\n",
       "      <th>type</th>\n",
       "      <th>so2</th>\n",
       "      <th>no2</th>\n",
       "      <th>rspm</th>\n",
       "      <th>spm</th>\n",
       "      <th>location_monitoring_station</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402345</th>\n",
       "      <td>362</td>\n",
       "      <td>August</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>Uttar Pradesh State Pollution Control Board</td>\n",
       "      <td>Residential, Rural and other Areas</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regional Office, Jawahar Nagar, Varanasi.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303299</th>\n",
       "      <td>NaN</td>\n",
       "      <td>January</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Ludhiana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential and others</td>\n",
       "      <td>10.7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PPCB Office Bldg.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39827.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91779</th>\n",
       "      <td>NaN</td>\n",
       "      <td>January</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential and others</td>\n",
       "      <td>12.7</td>\n",
       "      <td>17.1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Cadilla Bridge Narol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39844.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stn_code sampling_date  ... pm2_5     date\n",
       "402345      362        August  ...   NaN  41512.0\n",
       "303299      NaN       January  ...   NaN  39827.0\n",
       "91779       NaN       January  ...   NaN  39844.0\n",
       "\n",
       "[3 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "097eb495-c2a3-4334-99da-e8abb0b97c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Residential, Rural and other Areas', 'Industrial Area', nan,\n",
       "       'Sensitive Area', 'Industrial Areas', 'Residential and others',\n",
       "       'Sensitive Areas', 'Industrial', 'Residential', 'RIRUO',\n",
       "       'Sensitive'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieving the unique values in the 'type' column of the \"air\" dataframe\n",
    "air['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8561f9-1013-402e-b455-d1eb6ca850ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing multiple values in the 'type' column of the dataframe\n",
    "air['type'].replace('Residential, Rural and other Areas','Residential',inplace = True)\n",
    "air['type'].replace('Residential and others','Residential',inplace = True)\n",
    "air['type'].replace('Industrial Areas','Industrial',inplace = True)\n",
    "air['type'].replace('Industrial Area','Industrial',inplace = True)\n",
    "air['type'].replace('Sensitive Area','Sensitive',inplace = True)\n",
    "air['type'].replace('Sensitive Areas','Sensitive',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a1e4022-e5bd-46ae-b6e7-3562fd89a968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Andhra Pradesh', 'Arunachal Pradesh', 'Assam', 'Bihar',\n",
       "       'Chandigarh', 'Chhattisgarh', 'Dadra & Nagar Haveli',\n",
       "       'Daman & Diu', 'Delhi', 'Goa', 'Gujarat', 'Haryana',\n",
       "       'Himachal Pradesh', 'Jammu & Kashmir', 'Jharkhand', 'Karnataka',\n",
       "       'Kerala', 'Madhya Pradesh', 'Maharashtra', 'Manipur', 'Meghalaya',\n",
       "       'Mizoram', 'Nagaland', 'Odisha', 'Puducherry', 'Punjab',\n",
       "       'Rajasthan', 'Sikkim', 'Tamil Nadu', 'Telangana', 'Uttar Pradesh',\n",
       "       'Uttarakhand', 'Uttaranchal', 'West Bengal',\n",
       "       'andaman-and-nicobar-islands', 'Lakshadweep', 'Tripura'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieving the unique values in the 'state' column of the 'air' DataFrame\n",
    "air['state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf9e4d66-cf09-41e6-bfb0-55fdc16f0992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing a specific value in the 'state' column for maintaining consistency\n",
    "air['state'].replace('andaman-and-nicobar-islands', 'Andaman and Nicobar Islands', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e345797d-5804-417f-ab30-5be753cf83dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the 'date' column to datetime format and extract the 'year' column\n",
    "air['date'] = pds.to_datetime(air['date'],format='mixed')\n",
    "air['year'] = air['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b97340c-6d90-4a41-b1c5-c5ec4e1ba0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the missing 'year' values using ffill and converting them to integer type\n",
    "air['year'].fillna(method='ffill', inplace=True)\n",
    "air['year'] = air['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a905c9a-62ba-4c04-a94b-dbbb1f751194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values in Year column: 0\n"
     ]
    }
   ],
   "source": [
    "# checking null values in year column\n",
    "print(\"Null Values in Year column:\", air['year'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6932d740-bba3-4271-81c6-c3b3474122fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a separate dataFrame to show the proportion of missing values of each column\n",
    "missing = pds.DataFrame(air.isna().sum() / len(air))\n",
    "missing.columns = ['Proportion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18843152-c6af-4346-922a-904afa767dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Proportion\n",
      "pm2_5                             0.979\n",
      "spm                               0.545\n",
      "agency                            0.343\n",
      "stn_code                          0.331\n",
      "rspm                              0.092\n",
      "so2                               0.080\n",
      "location_monitoring_station       0.063\n",
      "no2                               0.037\n",
      "type                              0.012\n",
      "date                              0.000\n",
      "sampling_date                     0.000\n",
      "location                          0.000\n",
      "state                             0.000\n",
      "year                              0.000\n"
     ]
    }
   ],
   "source": [
    "# Displaying the columns sorted by the proportion of missing values in descending order\n",
    "print(missing.sort_values(by='Proportion', ascending=False).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550fbbf8-053c-4161-9568-c76da54c8e8d",
   "metadata": {},
   "source": [
    "#### Defining a function `get_state_median` that takes a state as an argument and calculates and prints the median values for \"Industrial, Residential, and Sensitive\" types for that state using the 'air' dataFrame. The function returns their median values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1dd7143-c066-4005-afff-57297fb2edb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pollutants = ['pm2_5', 'no2', 'so2', 'spm', 'rspm']\n",
    "\n",
    "def get_state_median(state):\n",
    "    # calculate the median values for no2 for the given state, grouped by type\n",
    "    state_medians = air[air['state'] == state].groupby('type')[pollutants].median().reset_index()\n",
    "\n",
    "    # return the state_medians dataframe\n",
    "    return state_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e1ef02b-6b5a-46a6-b0fd-540a33b67531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>no2</th>\n",
       "      <th>so2</th>\n",
       "      <th>spm</th>\n",
       "      <th>rspm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Industrial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>214.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>130.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          type  pm2_5   no2  so2    spm  rspm\n",
       "0   Industrial    NaN  22.2  5.4  214.0  76.0\n",
       "1  Residential    NaN  20.0  5.0  192.0  78.0\n",
       "2    Sensitive    NaN  13.0  4.6  130.0  51.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_state_median('Andhra Pradesh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "226a2407-5acc-4178-a71c-17ea95348517",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_values = get_state_median('Andhra Pradesh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5c6a630-befa-4d64-84f6-95a4bd21abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing 'so2' values in 'Andhra Pradesh' for Industrial, Residential, and Sensitive types\n",
    "air.loc[(air['state'] == 'Andhra Pradesh') & (air['type'].isin(['Industrial', 'Residential', 'Sensitive'])), 'so2'] = median_values['so2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8901f9b-b2e3-4283-89c3-271fcd9bc973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing 'no2' values in 'Andhra Pradesh' for Industrial, Residential, and Sensitive types\n",
    "air.loc[(air['state'] == 'Andhra Pradesh') & (air['type'].isin(['Industrial', 'Residential', 'Sensitive'])), 'no2'] = median_values['so2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cacd36f-1331-4d41-be92-8975dc4777c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in rspm: 40222\n",
      "Missing values in spm: 237387\n"
     ]
    }
   ],
   "source": [
    "# Print the number of missing values in the 'rspm' and 'spm' columns\n",
    "print(\"Missing Values in rspm:\", air['rspm'].isnull().sum())\n",
    "print(\"Missing values in spm:\" ,air['spm'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9201bbf2-b9cc-47ba-aac1-a966250526b5",
   "metadata": {},
   "source": [
    "#### Grouping the 'air' dataFrame by `location` and `type`, then using for loops to iterate through the groups. Sorting the values by 'date' and forward-fill missing values in the 'rspm' and 'spm' columns. The results are concatenated into a new dataFrame named data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2520f1e4-08f6-4ef6-889e-58edf279994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 'air' DataFrame by 'location' and 'type' and create a new dataFrame data\n",
    "df1 = dict(list(air.groupby(['location', 'type'])))\n",
    "data = pds.DataFrame()\n",
    "\n",
    "# Iterate through groups, sort by 'date', and forward-fill 'rspm' and 'spm' values\n",
    "for key in df1:\n",
    "    df2 = df1[key].sort_values('date')\n",
    "    df2['rspm'].fillna(method='ffill', inplace=True)\n",
    "    df2['spm'].fillna(method='ffill', inplace=True)\n",
    "    data = pd.concat([data, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df695fde-25de-4e13-82ca-fc5fab872516",
   "metadata": {},
   "source": [
    "#### Grouping the `data` dataFrame by **location** and **type**, then iterate through the groups. Within each group, we sort the values by 'date' and backward-fill missing values in the 'rspm' and 'spm' columns. The results are concatenated into a new DataFrame named **`data1`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53d5713a-1cf9-4130-9115-9257aa7e6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 'data' DataFrame by 'location' and 'type' and create a new DataFrame with backward-filled 'rspm' and 'spm' values\n",
    "df1 = dict(list(data.groupby(['location', 'type'])))\n",
    "data1 = pds.DataFrame()\n",
    "\n",
    "# Iterate through groups, sort by 'date', and backward-fill 'rspm' and 'spm' values\n",
    "for key in df1:\n",
    "    df2 = df1[key].sort_values('date')\n",
    "    df2['rspm'].fillna(method='bfill', inplace=True)\n",
    "    df2['spm'].fillna(method='bfill', inplace=True)\n",
    "    data1 = pd.concat([data1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8dfaac0-05a2-4467-8625-87bae5079fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the 'data1' df\n",
      "rspm: 4102\n",
      "spm: 47909\n"
     ]
    }
   ],
   "source": [
    "# Print the number of missing values in the 'rspm' and 'spm' columns of the 'data1' DataFrame\n",
    "print(\"Missing values in the 'data1' df\")\n",
    "print(\"rspm:\", data1['rspm'].isnull().sum())\n",
    "print(\"spm:\", data1['spm'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b94e0-cb36-4e04-821f-970cfd41b658",
   "metadata": {},
   "source": [
    "#### Grouping the `data1` dataFrame by 'state' and 'type', then iterate through the groups. Within each group, missing values in 'rspm' and 'spm' columns will be filled with the group-wise medians. The results are concatenated into a new dataFrame named **`data2`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d856278-ac34-4f5c-a9b7-74d45a0bc82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 'data1' DataFrame by 'state' and 'type' and create a new DataFrame with median-filled 'rspm' and 'spm' values\n",
    "df1 = dict(list(data1.groupby(['state', 'type'])))\n",
    "data2 = pds.DataFrame()\n",
    "\n",
    "# Iterate through groups and fill missing 'rspm' and 'spm' values with group-wise medians\n",
    "for key in df1:\n",
    "    df2 = df1[key]\n",
    "    df2['rspm'].fillna(df2['rspm'].median(), inplace=True)\n",
    "    df2['spm'].fillna(df2['spm'].median(), inplace=True)\n",
    "    data2 = pd.concat([data2, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f94f48c-7336-45f4-9af1-0f06d1817cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the 'data2' df\n",
      "rspm: 182\n",
      "spm: 1972\n"
     ]
    }
   ],
   "source": [
    "# Print the number of missing values in the 'rspm' and 'spm' columns of the 'data2' DataFrame\n",
    "print(\"Missing values in the 'data2' df\")\n",
    "print(\"rspm:\", data2['rspm'].isnull().sum())\n",
    "print(\"spm:\", data2['spm'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee4388-56ee-41b1-8f3d-095f6aa1a517",
   "metadata": {},
   "source": [
    "#### Grouping the `data2` dataFrame by 'type', then iterate through the groups. Within each group, missing values in 'rspm' and 'spm' columns are filled with the group-wise medians. The results are concatenated into a new dataFrame named **`data3`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d1be651-73cf-4595-a78b-601800dc381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 'data2' DataFrame by 'type' and create a new DataFrame with median-filled 'rspm' and 'spm' values\n",
    "df1 = dict(list(data2.groupby('type')))\n",
    "data3 = pds.DataFrame()\n",
    "\n",
    "# Iterate through groups and fill missing 'rspm' and 'spm' values with group-wise medians\n",
    "for key in df1:\n",
    "    df2 = df1[key]\n",
    "    df2['rspm'].fillna(df2['rspm'].median(), inplace=True)\n",
    "    df2['spm'].fillna(df2['spm'].median(), inplace=True)\n",
    "    data3 = pds.concat([data3, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0fa7f3a-f4c2-4088-82f3-9a337953a16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the data3 df\n",
      "rspm: 0\n",
      "spm: 1304\n"
     ]
    }
   ],
   "source": [
    "# Print the number of missing values in the 'rspm' and 'spm' columns of the 'data3' DataFrame\n",
    "print(\"Missing values in the data3 df\")\n",
    "print(\"rspm:\", data3['rspm'].isnull().sum())\n",
    "print(\"spm:\", data3['spm'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b04241a-0459-4b7f-8727-8464ec839064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "Residential    265963\n",
       "Industrial     148071\n",
       "Sensitive       15011\n",
       "RIRUO            1304\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the count of each type in the 'data3' DataFrame\n",
    "data3['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e078b12-36ed-4480-a32b-08effcf045f4",
   "metadata": {},
   "source": [
    "#### Resetting the index of the **`data3`** dataFrame and dropping unnecessary columns to obtain a cleaner dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83fad072-6a9b-4bd6-aff4-55ba9549cc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>type</th>\n",
       "      <th>so2</th>\n",
       "      <th>no2</th>\n",
       "      <th>rspm</th>\n",
       "      <th>spm</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-01-02</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.3</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-01-03</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.3</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-01-04</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.3</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-01-05</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.3</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990-01-06</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            state   location        type  so2  ...   spm  pm2_5       date  year\n",
       "0  Andhra Pradesh  Hyderabad  Industrial  5.0  ...  82.0    NaN 1990-01-02  1990\n",
       "1  Andhra Pradesh  Hyderabad  Industrial  NaN  ...  82.0    NaN 1990-01-03  1990\n",
       "2  Andhra Pradesh  Hyderabad  Industrial  NaN  ...  82.0    NaN 1990-01-04  1990\n",
       "3  Andhra Pradesh  Hyderabad  Industrial  NaN  ...  82.0    NaN 1990-01-05  1990\n",
       "4  Andhra Pradesh  Hyderabad  Industrial  NaN  ...  82.0    NaN 1990-01-06  1990\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset index and drop unnecessary columns from the 'data3' DataFrame\n",
    "data3.reset_index(inplace=True)\n",
    "data3.drop(columns=['index', 'stn_code', 'sampling_date', 'agency', 'location_monitoring_station'], inplace=True)\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3b28659-71ae-4d87-8627-4f32cd1fe220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state            0\n",
       "location         0\n",
       "type             0\n",
       "so2          59271\n",
       "no2          41067\n",
       "rspm             0\n",
       "spm           1304\n",
       "pm2_5       421035\n",
       "date             4\n",
       "year             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the 'data3' DataFrame\n",
    "data3.isnull().sum()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbc98ef-86da-4091-b2f9-be8bea01f354",
   "metadata": {},
   "source": [
    "#### Using the `to_csv` method to save a copy of the final cleaned data stored in the 'data3' dataFrame to a CSV file named 'air_quality_cleaned.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdc3767a-5f6d-49bd-a4f0-47ee091f1561",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.to_csv('air_quality_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
